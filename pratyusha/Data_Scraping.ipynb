{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PratyushaChatterjee/ML-works/blob/main/Data_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxidoxedS8-F",
        "outputId": "4e86b8df-8e3a-4766-be12-f9653bbf68b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.21.0)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.25.1)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.11.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.7)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Choose the type of search:\n",
            "1. Job search from LinkedIn\n",
            "2. Company-based search from a company's website\n",
            "3. Generalized search from the internet\n",
            "Enter your choice (1/2/3): 3\n",
            "Enter your search query: aws alternatives\n",
            "Results saved to search_results.csv\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "import csv\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "def linkedin_job_search(query):\n",
        "    # LinkedIn job search\n",
        "    url = f\"https://www.linkedin.com/jobs/search/?keywords={query}\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    jobs = soup.find_all('div', class_='job-search-card')\n",
        "    #print(jobs)\n",
        "    results = []\n",
        "    for job in jobs:\n",
        "        title_elem = job.find('span', class_='sr-only')\n",
        "        company_elem = job.find('a', class_='hidden-nested-link')\n",
        "\n",
        "        if title_elem and company_elem:\n",
        "            title = title_elem.text.strip()\n",
        "            company = company_elem.text.strip()\n",
        "            results.append({'Title': title, 'Company': company})\n",
        "    return results\n",
        "def company_website_search(company_name):\n",
        "    # Company-based search from company's website\n",
        "    url = f\"https://www.quickcompany.in/search?q={company_name}\"\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    # Assuming search results are in a specific format, adjust as needed\n",
        "    results =soup.find_all('a')\n",
        "    company_results = []\n",
        "    for result in results:\n",
        "      try:\n",
        "       if result['href']!='/' and  result['href']!='#' :\n",
        "        title = result.text.strip()\n",
        "        company_results.append({'Title': title, 'URL': result['href']})\n",
        "      except:\n",
        "          pass\n",
        "    return company_results\n",
        "def general_search(query):\n",
        "    # Generalized search from the internet\n",
        "    url = f\"https://www.google.com/search?q={query}\"\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    # Parse and extract relevant information from Google search results\n",
        "    results = []\n",
        "    search_results = soup.find_all('a')\n",
        "    #print(search_results)\n",
        "    for result in search_results:\n",
        "     try:\n",
        "        title = result.find('h3').div.text.strip()\n",
        "        link = result['href'][30:]\n",
        "        results.append({'Title': title, 'Link': link})\n",
        "     except:\n",
        "         pass\n",
        "    return results\n",
        "\n",
        "\n",
        "def save_to_csv(results):\n",
        "    if not results:\n",
        "        print(\"No results to save.\")\n",
        "        return\n",
        "\n",
        "    with open('search_results.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = results[0].keys() if results else []\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for row in results:\n",
        "            writer.writerow(row)\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"Choose the type of search:\")\n",
        "    print(\"1. Job search from LinkedIn\")\n",
        "    print(\"2. Company-based search from a company's website\")\n",
        "    print(\"3. Generalized search from the internet\")\n",
        "\n",
        "    choice = input(\"Enter your choice (1/2/3): \")\n",
        "\n",
        "    if choice == '1':\n",
        "        query = input(\"Enter job title or keyword: \")\n",
        "        results = linkedin_job_search(query)\n",
        "    elif choice == '2':\n",
        "        company_name = input(\"Enter company name: \")\n",
        "        results = company_website_search(company_name)\n",
        "    elif choice == '3':\n",
        "        query = input(\"Enter your search query: \")\n",
        "        results = general_search(query)\n",
        "    else:\n",
        "        print(\"Invalid choice. Please enter 1, 2, or 3.\")\n",
        "        return\n",
        "\n",
        "    save_to_csv(results)\n",
        "    print(\"Results saved to search_results.csv\")\n",
        "\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import csv\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "def linkedin_job_search(query):\n",
        "    url = f\"https://www.linkedin.com/jobs/search/?keywords={query}\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    jobs = soup.find_all('div', class_='job-search-card')\n",
        "    results = []\n",
        "    for job in jobs:\n",
        "        title_elem = job.find('span', class_='sr-only')\n",
        "        company_elem = job.find('a', class_='hidden-nested-link')\n",
        "        if title_elem and company_elem:\n",
        "            title = title_elem.text.strip()\n",
        "            company = company_elem.text.strip()\n",
        "            results.append({'Title': title, 'Company': company})\n",
        "    return results\n",
        "\n",
        "def company_website_search(company_name):\n",
        "    url = f\"https://www.quickcompany.in/search?q={company_name}\"\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    results = soup.find_all('a')\n",
        "    company_results = []\n",
        "    for result in results:\n",
        "        try:\n",
        "            if result['href'] != '/' and result['href'] != '#':\n",
        "                title = result.text.strip()\n",
        "                company_results.append({'Title': title, 'URL': result['href']})\n",
        "        except:\n",
        "            pass\n",
        "    return company_results\n",
        "\n",
        "def general_search(query):\n",
        "    url = f\"https://www.google.com/search?q={query}\"\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    results = []\n",
        "    for item in soup.find_all('div', class_='BNeawe s3v9rd AP7Wnd'):\n",
        "        try:\n",
        "            text = item.get_text()\n",
        "            if text and text not in results:  # Ensure uniqueness\n",
        "                results.append(text)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    return results\n",
        "\n",
        "def save_to_csv(results):\n",
        "    if not results:\n",
        "        print(\"No results to save.\")\n",
        "        return\n",
        "\n",
        "    with open('search_results.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = results[0].keys() if isinstance(results[0], dict) else ['Result']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for row in results:\n",
        "            if isinstance(row, dict):\n",
        "                writer.writerow(row)\n",
        "            else:\n",
        "                writer.writerow({'Result': row})\n",
        "\n",
        "def main():\n",
        "    print(\"Choose the type of search:\")\n",
        "    print(\"1. Job search from LinkedIn\")\n",
        "    print(\"2. Company-based search from a company's website\")\n",
        "    print(\"3. Generalized search from the internet\")\n",
        "\n",
        "    choice = input(\"Enter your choice (1/2/3): \")\n",
        "\n",
        "    if choice == '1':\n",
        "        query = input(\"Enter job title or keyword: \")\n",
        "        results = linkedin_job_search(query)\n",
        "    elif choice == '2':\n",
        "        company_name = input(\"Enter company name: \")\n",
        "        results = company_website_search(company_name)\n",
        "    elif choice == '3':\n",
        "        query = input(\"Enter your search query: \")\n",
        "        results = general_search(query)\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid choice. Please enter 1, 2, or 3.\")\n",
        "        return\n",
        "\n",
        "    save_to_csv(results)\n",
        "    print(\"Results saved to search_results.csv\")\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMqikXw9yt6O",
        "outputId": "00f8ec68-0676-4ec7-8589-ffea6c4299ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choose the type of search:\n",
            "1. Job search from LinkedIn\n",
            "2. Company-based search from a company's website\n",
            "3. Generalized search from the internet\n",
            "Enter your choice (1/2/3): 3\n",
            "Enter your search query: cloud service alternatives\n",
            "Results saved to search_results.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMmo7FaC43s79K/zZYzSzb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}